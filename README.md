## ğŸ”¤ Hangman Game with N-Gram Intelligence (Aprilâ€™25)

This project enhances the classic Hangman game using Natural Language Processing techniques. It utilizes N-Gram language models to predict the next most probable letter based on the current word pattern. The model combines multiple N-Gram probabilities (unigram, bigram, trigram) using interpolation to improve prediction accuracy.

### ğŸš€ Features
- ğŸ“ˆ Trained and interpolated multiple N-Gram models to make intelligent letter guesses.
- ğŸ§  Adaptive guess function that dynamically adjusts based on game progress.
- ğŸ“Š Achieved ~66% accuracy on a test dataset of real English words.
- ğŸ› ï¸ Built in Python with custom NLP logic and probability handling.

### ğŸ§° Tech Stack
- Python
- N-Gram Language Models
- NLP (Natural Language Processing)

### ğŸ“‚ Future Work
- Add GUI for interactive gameplay.
- Extend to multilingual support.
- Improve accuracy with smoothing techniques or neural models.

