## 🔤 Hangman Game with N-Gram Intelligence (April’25)

This project enhances the classic Hangman game using Natural Language Processing techniques. It utilizes N-Gram language models to predict the next most probable letter based on the current word pattern. The model combines multiple N-Gram probabilities (unigram, bigram, trigram) using interpolation to improve prediction accuracy.

### 🚀 Features
- 📈 Trained and interpolated multiple N-Gram models to make intelligent letter guesses.
- 🧠 Adaptive guess function that dynamically adjusts based on game progress.
- 📊 Achieved ~66% accuracy on a test dataset of real English words.
- 🛠️ Built in Python with custom NLP logic and probability handling.

### 🧰 Tech Stack
- Python
- N-Gram Language Models
- NLP (Natural Language Processing)

### 📂 Future Work
- Add GUI for interactive gameplay.
- Extend to multilingual support.
- Improve accuracy with smoothing techniques or neural models.

